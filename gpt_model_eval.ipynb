{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of GPT Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the file data\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generate a book summary with genres Science Fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Generate a book summary with genres Fantasy:\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Generate a book summary with genres Crime Fict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Generate a book summary with genres Fiction, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Generate a book summary with genres War novel,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  Generate a book summary with genres Science Fi...\n",
       "1  Generate a book summary with genres Fantasy:\\n...\n",
       "2  Generate a book summary with genres Crime Fict...\n",
       "3  Generate a book summary with genres Fiction, N...\n",
       "4  Generate a book summary with genres War novel,..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "filename = 'data/5000_booksummaries.zip'\n",
    "tokens_df = pd.read_csv(filename)\n",
    "tokens_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test/eval data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into train (80%), val (10%), test (10%)\n",
    "train_data, test_eval_dataset = train_test_split(tokens_df, test_size=0.2, random_state=8)\n",
    "eval_set, test_set = train_test_split(test_eval_dataset, test_size=0.5, random_state=8)\n",
    "\n",
    "# create HuggingFace Datasets\n",
    "train_ds = Dataset.from_pandas(train_data)\n",
    "eval_ds = Dataset.from_pandas(eval_set)\n",
    "test_ds = Dataset.from_pandas(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dir depending on where it is\n",
    "\"\"\"from transformers import pipeline, set_seed\n",
    "\n",
    "# vanilla, pretrained GPT\n",
    "gpt_generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "gpt_generated_text = gpt_generator(text, max_length=50, num_return_sequences=3)\n",
    "\n",
    "# print outputs individually\n",
    "for gt in gpt_generated_text:\n",
    "    print(\"--------- New Generated Text----------- \\n\")\n",
    "    print(gt['generated_text'])\"\"\"\n",
    "\n",
    "# 3 epochs\n",
    "checkpoint_3 = '/Users/alexisechano/Desktop/models/content_3/model_config'\n",
    "model = GPT2LMHeadModel.from_pretrained(checkpoint_3, local_files_only=True)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(checkpoint_3, local_files_only=True)\n",
    "\n",
    "# 5 epochs\n",
    "#checkpoint_3 = '/Users/alexisechano/Desktop/models/content_3/model_config'\n",
    "#model = GPT2LMHeadModel.from_pretrained(checkpoint_3, local_files_only=True)\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained(checkpoint_3, local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a book summary with genre science fiction:\n",
      " The story begins with the arrival of the first human colonists on the planet, the USS Enterprise-D, to investigate a mysterious anomaly in space. The ship is attacked by an alien race known as the X-Men, and the crew is forced to abandon the ship in an attempt to escape. Meanwhile, a group of humans, led by a scientist named Dr. James Hansen, have been attempting to find a cure for a deadly virus. As they approach the anomaly, they encounter an unknown force that threatens to wipe out all life on Earth. However, soon after, an explosion destroys the spaceship, killing all crew members, including the three scientists. Hansen's team manages to save the humans and\n"
     ]
    }
   ],
   "source": [
    "# load input prompt\n",
    "input_prompt = \"Generate a book summary with genre science fiction:\\n\"\n",
    "inputs = tokenizer(input_prompt, return_tensors=\"pt\")\n",
    "\n",
    "# generate output from pretrained experiments (see baseline file)\n",
    "outputs = model.generate(**inputs, \n",
    "    max_length=150, \n",
    "    num_beams=2, \n",
    "    no_repeat_ngram_size=2, \n",
    "    do_sample=True,\n",
    "    early_stopping=True)\n",
    "\n",
    "# decode output and print out summary\n",
    "output = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert_score in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (0.3.13)\n",
      "Requirement already satisfied: torch>=1.0.0 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from bert_score) (1.13.1)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from bert_score) (4.24.0)\n",
      "Requirement already satisfied: requests in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from bert_score) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from bert_score) (4.64.0)\n",
      "Requirement already satisfied: numpy in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from bert_score) (1.21.5)\n",
      "Requirement already satisfied: matplotlib in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from bert_score) (3.5.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from bert_score) (22.0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from bert_score) (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from pandas>=1.0.1->bert_score) (2022.7)\n",
      "Requirement already satisfied: typing_extensions in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from torch>=1.0.0->bert_score) (4.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from transformers>=3.0.0->bert_score) (2022.7.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from transformers>=3.0.0->bert_score) (0.10.1)\n",
      "Requirement already satisfied: importlib-metadata in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from transformers>=3.0.0->bert_score) (4.11.3)\n",
      "Requirement already satisfied: filelock in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from transformers>=3.0.0->bert_score) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from transformers>=3.0.0->bert_score) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from transformers>=3.0.0->bert_score) (0.11.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from matplotlib->bert_score) (9.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from matplotlib->bert_score) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from matplotlib->bert_score) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from matplotlib->bert_score) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from matplotlib->bert_score) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from requests->bert_score) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from requests->bert_score) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from requests->bert_score) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from requests->bert_score) (1.26.13)\n",
      "Requirement already satisfied: six>=1.5 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert_score) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/alexisechano/opt/anaconda3/envs/cs224n/lib/python3.7/site-packages (from importlib-metadata->transformers>=3.0.0->bert_score) (3.11.0)\n"
     ]
    }
   ],
   "source": [
    "# use BERTScores to analyze\n",
    "%pip install bert_score\n",
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_to_prompt(whole_text):\n",
    "    tok = whole_text.index(':')\n",
    "    return whole_text[:tok+2] # returns text with new line\n",
    "\n",
    "def generate_summary_from_prompt(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # generate output from pretrained experiments (see baseline file)\n",
    "    outputs = model.generate(**inputs, \n",
    "        max_length=150, \n",
    "        num_beams=2, \n",
    "        no_repeat_ngram_size=2, \n",
    "        do_sample=True,\n",
    "        early_stopping=True)\n",
    "\n",
    "    # decode output and return out summary\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# run model to generate predictions\n",
    "references = []\n",
    "predictions = []\n",
    "truncated_test_inputs = []\n",
    "\n",
    "for example in test_ds:\n",
    "    input = example[\"Text\"]\n",
    "    prompt_only = truncate_to_prompt(input)\n",
    "    truncated_test_inputs.append(prompt_only)\n",
    "    references.append(input)\n",
    "    \n",
    "    # predict summaries\n",
    "    predictions.append(generate_summary_from_prompt(prompt_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': [0.8472938537597656, 0.8493414521217346, 0.856782853603363], 'recall': [0.8143622875213623, 0.825314998626709, 0.8225511908531189], 'f1': [0.8305017352104187, 0.8371558785438538, 0.8393180966377258], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.24.0)'}\n"
     ]
    }
   ],
   "source": [
    "results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
